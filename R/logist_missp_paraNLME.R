#' Parametric nonlinear mixed effects model (NLME) approach: When true data are generated by the arctangent model, the parametric NLME procedure is performed under the (missepcified) logistic model.
#'
#' @param n number of sample size.
#' @param model a character string for a nonlinear model: \code{"logist"} or \code{"arctan"}.
#' @param num.boot number of bootsrap replicates.
#' @param dat a data frame of the generated data set.
#' @param time.length number of data points at which predictors are required for each individual longitudinal trajectory. This time point for graphs to be plotted.
#' @param true.gam1 a true scale parameter for \code{gam1} in the arctangent function, see \code{arctanf()}.
#' @param true.gam3 a true parameter for \code{gam3}, which determines steepness of the arctangent function, see \code{arctanf()}.
#' @param para1 an initial parameter for \code{theta1}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para2 an initial intercept parameter for the inflection point \code{theta2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para3 an initial (p-1)-length of coefficient vector of subject specific covariates for the inflection point \code{theta2}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param para4 an initial parameter for \code{theta3}, which is used for the parametric nonlinear mixed effects model (NLME) approach.
#' @param eps.sd a true scale parameter of the within-subject error term in the longitudinal model.
#' @param dist a character string for the distribution of within-subject error term in the longitudinal model. Default is \code{"normal"}.
#
#'
#'
#
#'
#' @return A list of
#'
#'        \item{est.beta}{the (p-1)-length of estimated coefficient vector of subjec-specific covariates in the log-normal model for inflection points.}
#'        \item{est.beta0}{estimated intercept of the log-normal model for inflection points.}
#'        \item{est.str.beta}{the (p-1)-length of estimated standard errors of the coefficient vector of subject-specific covariates in the log-normal model for inflection points.}
#'        \item{est.str.beta0}{estimated standard errors of the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta0}{estimated lower bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.upper.beta0}{estimated upper bound of the 95\% confidence interval for beta0, which is the intercept of the log-normal model for inflection points.}
#'        \item{cp.lower.beta}{estimated lower bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{cp.upper.beta}{estimated upper bound of the 95\% confidence interval for beta, which is the (p-1)-length of the coefficient vector of subject specific covariates in the log-normal model for inflection points.}
#'        \item{est.rand.ef}{estimated random effects in the log normal model for the inflection points.}
#'        \item{est.logT}{the n-length of the estimated inflection points vector, where each element is the individual estimated inflection point.}
#'        \item{true.logT}{the n-length of the true inflection points vector, where each element is the true individual inflection point.}
#'        \item{new.pred.data}{a time.length x 5 x n array of data set to generate boostrap estimates, which includes ID, log scaled ages, subject specfici covariates, true longitudinal trajectories and estimated longitudinal trajectories for each subject.}
#'        \item{true.first.deriv}{a time.length x n array of the first derivatives of the true longitudinal trajectories, where each column is the first derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{true.second.deriv}{a time.length x n array of the second derivatives of the true longitudinal trajectories, where each column is the second derivatives of the true longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.first.deriv}{a time.length x n array of the estiamted first derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{est.second.deriv}{a time.length x n array of the estiamted second derivatives of longitudinal trajectories, where each column is the estimated second derivatives of longitudinal responses corresponding subject-specific log scaled ages in \code{new.pred.data} for each subject.}
#'        \item{boot.est.logT}{a n x num.boot array of the bootstrap estimated inflection points, where each row is a num.boot-length of boostrap estimates of the inflection point for each subject.}
#'        \item{ind.sd}{the n-length of the estimated boostrap standard deviations, where each element is the estimated standard deviation of the bootstrap estimates for each subject (each row of \code{boot.est.logT}).}
#'        \item{cp.boot}{a n x 2 array of the 95\% bootstrap confidence intervals, where each row has the lower bound and the upper bound of the 95\% confidence interval for the individual inflection point (i.e., 25th and 97.5th percentiles of the increasing ordered boostrap estimates for each row of \code{boot.est.logT}).}
#'
#'
#'
#' @export
#'
#' @examples
#'
#' library(HDChangePoint)
#'
#' ## Specify parameters to generate true data
#' n=80;
#' model="arctan";
#' p=2;
#' bb0=2;
#' bb=0.1;
#' x.sd=0.3;
#' v1=5;
#' v2=7;
#' dist="normal";
#' eps.sd=0.05;
#' u.sd=0.05;
#'
#'
#' ## Specify parameters for the parametric NLME procedure
#'
#' num.boot=1000;
#' true.gam1=2.45/pi;
#' true.gam3=pi/1.1;
#' time.length=45;
#' eps.sd=0.05;
#' dist="normal";
#' para1=6.5;
#' para2=5.3;
#' para3=0;
#' para4=1;
#'
#' ## generate data with seed number
#' set.seed(22)
#' outdat<-mydata(n=n, model=model, p=p, bb0=bb0, bb=bb, x.sd=x.sd, v1=v1, v2=v2, dist=dist, eps.sd=eps.sd, u.sd=u.sd)
#'
#' ## Do parametric NLME estimation
#' results<- main.logistic.missp.nlme(n=n, model=model, dat=outdat, num.boot=num.boot, time.length=time.length,
#'                                    true.gam1=true.gam1, true.gam3=true.gam3, para1=para1,
#'                                    para2=para2, para3=para3, para4=para4, eps.sd=eps.sd, dist=dist)
#'
#'



main.logistic.missp.nlme<-function(n=80, model="arctan",  num.boot=1000, dat=outdat, time.length=20, true.gam1=2.45/pi, true.gam3=pi/1.1,  para1=3.1, para2=0.2, para3=0.2, para4=1.5, eps.sd=0.05, dist="normal"){


  ################################################################
  ## data structure constructed by each subject:  List format  ###
  ## include subject i, covariate log age,                     ###
  ##         true nonlinear function omega, error term         ###
  ##         true inflection points, true beta,                ###
  ##         true covariate W associated with inflection pts   ###
  ################################################################

  tms.dat<-vector("list", n)


  for(id in 1:n){

    sub.dat<-dat[dat$subj.id==id, ]
    ll<-dim(sub.dat)[1]

    subj<-sub.dat$subj.id
    true.z<-sub.dat$true_z
    W.cov<-sub.dat$cov.W
    gender<-sub.dat$sex

    if (dist=="normal"){
      eps<-rnorm(ll,0,eps.sd)
    }


    logS<-sub.dat$xx
    tr.z<-unique(sub.dat$true_z)

    #omega<-w(logS, tr.z, model)
    omega<-sub.dat$omega
    tms<-omega+eps #sub.dat$yy

    tms.dat[[id]]<-cbind(subj,tms, omega, logS, W.cov, gender, eps, true.z)  # true.t,eps,


  }


  ## create data.frame from list type of data
  gendat<-do.call("rbind.data.frame", tms.dat)

  ## Create grouped Data
  newgrdata<-groupedData(tms~logS|subj, data=gendat, order.groups=FALSE)




  #################################################################################################################################################
  ## Fit nonlinear mixed model using nlme() in NLME package to estimate fixed effects and random effects
  ## in longitudinal model: true data are generated by logistic model
  ## tms: longitudinal response vector for a subject i and jth visit.
  ## logistf: fitted nonlinear model.
  ## theta1: fixed effect
  ## theta2: log transformed inflection points, which is modeled by linear relationship with
  ##         subject specific covariate W.cov, containig fixed effect beta and random effects u
  ##
  ## logS: main covariate in the logitudinal model
  ## model: tms ~logistf(theta1, theta2,  logS)
  ## fixed: two sided linear model in the form of f1~x1, where f1: names of parameters, x1: covariates in the ##linear relationship with f1
  ##       eg. theat1 ~1
  ## random: two sided formula in the form of r1~x1, where r1: names of parameters, x1 specifies the random effects model for the parameter r1
  ## groups: ~g1 or ~g1/g2../gQ, specify the partitions of the data over which the random effects vary
  ## start: list of initial estimates for the fixed effects and random effects
  ## method: "REML" or "ML", modle is fit by maximizing the restricted log liklihood or log-likelihood.
  ## verbose: TRUE means information on the evoluation of the interative algorithm is printed. Default is FALSE.
  ###################################################################################################################################################


  tms.nlme<-nlme(tms~logistft(theta1, theta2, theta3, logS), fixed=list(theta1~1, theta2~1+W.cov, theta3~1) , random=list(theta2~1),
                 data= newgrdata, groups=~subj,  start=list(fixed=c(para1,para2,para3, para4)), method="ML", verbose=FALSE)


  #############################################
  ### estimates of fixed effect: theta1, beta #
  #############################################

  est.theta1<-summary(tms.nlme)$tTable[,"Value"]["theta1"]
  est.beta<-summary(tms.nlme)$tTable[,"Value"]["theta2.W.cov"]
  est.beta0<-summary(tms.nlme)$tTable[,"Value"]["theta2.(Intercept)"]
  est.theta3<-summary(tms.nlme)$tTable[,"Value"]["theta3"]

  #####################################
  ## standard errors of fixed effects #
  #####################################


  est.str.theta1<-summary(tms.nlme)$tTable[,"Std.Error"]["theta1"]
  est.str.beta<-summary(tms.nlme)$tTable[,"Std.Error"]["theta2.W.cov"]
  est.str.theta3<-summary(tms.nlme)$tTable[,"Std.Error"]["theta3"]
  est.str.beta0<-summary(tms.nlme)$tTable[,"Std.Error"]["theta2.(Intercept)"]


  ##########################
  ##  coverage probability #
  ##########################
  cp.fixed<-intervals(tms.nlme, level=0.95, which=c("fixed"))

  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.theta1<- cp.fixed$fixed["theta1","lower"]
  cp.upper.theta1<- cp.fixed$fixed["theta1","upper"]

  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta0<- cp.fixed$fixed["theta2.(Intercept)","lower"]
  cp.upper.beta0<- cp.fixed$fixed["theta2.(Intercept)","upper"]

  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.beta<- cp.fixed$fixed["theta2.W.cov","lower"]
  cp.upper.beta<- cp.fixed$fixed["theta2.W.cov","upper"]

  ###########################################
  ##  coverage probability for fixed effects#
  ###########################################
  cp.lower.theta3<-cp.fixed$fixed["theta3","lower"]
  cp.upper.theta3<-cp.fixed$fixed["theta3","upper"]


  #####################
  ##  scale parameter #
  #####################

  ## within-individual
  sig.eps<-tms.nlme$sigma


  ###############################################################
  ## Extract Random effects with augmented data from groupedData#
  ###############################################################
  augmented.dat<-random.effects(tms.nlme, augFrame=T, data=newgrdata)
  est.rand.ef<-augmented.dat[,"theta2.(Intercept)"]

  ##################################################
  ## estimate inflection points (random effects)  ##
  ## estimate bias for inflection points          ##
  ##################################################

  est.logT<-est.beta0+est.beta*augmented.dat[,"W.cov"]+est.rand.ef  # estimated logT
  true.logT<-augmented.dat[,"true.z"]



  #####################################################################################################
  ### predict(): popoulation prediction (random effects=0) at polulation level 0                    ###
  ###              within group predictions (use estimated random effects) at individual level 1    ###
  #####################################################################################################



  #########################################
  # predicted total motor score           #
  #########################################



  new.pred.data<- array(0, dim=c(time.length, 5, n),
                        dimnames=list(paste("visit",1:time.length,sep=""), c("pseudo.id","pseudo.logS","pseudo.wcov", "ture.pseudo.tms", "est.pseudo.tms"), paste("ID",1:n,sep="")));



  for (id in 1:n){

    group<-newgrdata[newgrdata$subj==id, ]


    pseudo.xy<-approx(group[,"logS"], group[,"omega"], n=time.length)
    pseudo.logS<-pseudo.xy$x
    pseudo.omega<-pseudo.xy$y

    pseudo.id<-rep(id, time.length)
    pseudo.wcov<-rep(unique(group[,"W.cov"]), time.length)

    if (dist=="normal"){
      pseudo.err<-rnorm(time.length,0, eps.sd)

    }

    pseudo.tms<-pseudo.omega+pseudo.err

    new.dat<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms)


    pred.data<-data.frame(subj= new.dat[,"pseudo.id"], logS= new.dat[,"pseudo.logS"],
                          W.cov=new.dat[ ,"pseudo.wcov"])

    ## predictions for tms  based on newd
    pred.traj<-predict(tms.nlme, pred.data, level=1)
    new.pred.data[,,id]<-cbind(pseudo.id, pseudo.logS, pseudo.wcov,  pseudo.tms, pred.traj)

  }


  boot.est.logT<-array(0, dim=c(n, num.boot),
                       dimnames=list(paste("id",1:n,sep=""),paste("boot",1:num.boot,sep=""))
  )

  for(b in 1:num.boot){


    boot.pred.data<-vector("list", n)



    for(id in 1:n){

      ind.pred.data<-new.pred.data[,,id]
      boot.size<-dim(ind.pred.data)[[1]]
      err<-ind.pred.data[, "ture.pseudo.tms"]-ind.pred.data[, "est.pseudo.tms"]
      err.boot<-sample(err, size=boot.size, replace=TRUE)
      boot.tms<-ind.pred.data[, "est.pseudo.tms"]+err.boot
      boot.pred.data[[id]]<-cbind(ind.pred.data, boot.tms)

    }

    boot.data<-do.call("rbind.data.frame", boot.pred.data)


    boot.tms.nlme<-nlme(boot.tms~logistft(theta1, theta2, theta3, pseudo.logS), fixed=list(theta1~1, theta2~1+pseudo.wcov, theta3~1) , random=list(theta2~1),
                        data=boot.data, groups=~pseudo.id,  start=list(fixed=c(para1,para2,para3, para4)), method="ML", verbose=FALSE)


    boot.est.beta<-summary(boot.tms.nlme)$tTable[,"Value"]["theta2.pseudo.wcov"]
    boot.est.beta0<-summary(boot.tms.nlme)$tTable[,"Value"]["theta2.(Intercept)"]



    boot.augmented.dat<-random.effects(boot.tms.nlme, augFrame=T, data=boot.data)
    boot.est.rand.ef<-boot.augmented.dat[,"theta2.(Intercept)"]



    boot.est.logT[,b]<-boot.est.beta0+boot.est.beta*boot.augmented.dat[,"pseudo.wcov"]+boot.est.rand.ef  # estimated logT


  }


  ind.sd<-rep(100,n);
  cp.boot<-array(0, dim=c(n, 2),
                 dimnames=list(paste("id",1:n,sep=""),c("95% lower", "95% upper"))
  )


  for (id in 1:n){
    ind.boot<-boot.est.logT[id, ]
    ind.sd[id]<-sd(ind.boot)
    order.ind.boot<-sort(ind.boot)
    cp.boot[id,]<-quantile(order.ind.boot, prob=c(0.025, 0.975))
  }



  #########################################################
  # First and Second Derivative of Longitudinal Responses #
  #########################################################


  true.first.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  true.second.deriv<-array(0, dim=c(time.length,n),
                           dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))

  est.first.deriv<-array(0, dim=c(time.length,n),
                         dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))
  est.second.deriv<-array(0, dim=c(time.length,n),
                          dimnames=list(paste("visit",1:time.length,sep=""),paste("ID",1:n,sep="")))


  for (id in 1:n){

    sub.logs<-new.pred.data[,"pseudo.logS",id]


    true.first.deriv[,id]<-arctan_first_deriv_ft(true.gam1, true.logT[id], true.gam3,  sub.logs)
    true.second.deriv[,id]<-arctan_second_deriv_ft(true.gam1,  true.logT[id], true.gam3,  sub.logs)


    est.first.deriv[,id]<-logist_first_deriv_ft(est.theta1,  est.logT[id], est.theta3,  sub.logs)
    est.second.deriv[,id]<-logist_second_deriv_ft(est.theta1,  est.logT[id], est.theta3,  sub.logs)


  }



  return(list( new.pred.data=new.pred.data,
               est.beta=est.beta,est.beta0=est.beta0,

               est.str.beta=est.str.beta, est.str.beta0=est.str.beta0, #standard errors
               cp.lower.beta0=cp.lower.beta0, cp.upper.beta0=cp.upper.beta0, cp.lower.beta=cp.lower.beta,

               cp.upper.beta=cp.upper.beta, #coverage prob

               #newgrdata=newgrdata,
               sig.eps=sig.eps,

               est.rand.ef=est.rand.ef,
               est.logT=est.logT, true.logT=true.logT,
               ## bias of derivatives
               true.first.deriv=true.first.deriv,  true.second.deriv= true.second.deriv,  est.first.deriv= est.first.deriv, est.second.deriv=est.second.deriv,

               boot.est.logT=boot.est.logT,  ind.sd=ind.sd, cp.boot=cp.boot  ))

}

